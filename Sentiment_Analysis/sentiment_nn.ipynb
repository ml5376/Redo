{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from sentiment_data import (\n",
    "    download_data,\n",
    "    load_sentiment_data,\n",
    "    load_vocab,\n",
    "    SentimentDataset,\n",
    "    collate\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5, 5) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples: 9154\n",
      "number of validation samples: 3133\n",
      "number of test samples: 3083\n"
     ]
    }
   ],
   "source": [
    "i2dl_exercises_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "data_root = os.path.join(i2dl_exercises_path, \"datasets\", \"SentimentData\")\n",
    "base_dir = download_data(data_root)\n",
    "vocab = load_vocab(base_dir)\n",
    "train_data, val_data, test_data = load_sentiment_data(base_dir, vocab)\n",
    "\n",
    "print(\"number of training samples: {}\".format(len(train_data)))\n",
    "print(\"number of validation samples: {}\".format(len(val_data)))\n",
    "print(\"number of test samples: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      " You'd better choose Paul Verhoeven's even if you have watched it.\n",
      "\n",
      "Tokens: \n",
      " ['you', 'd', 'better', 'choose', 'paul', 'verhoeven', 's', 'even', 'if', 'you', 'have', 'watched', 'it']\n",
      "\n",
      "Indices: \n",
      " [20, 232, 107, 1999, 855, 4624, 16, 64, 35, 20, 26, 214, 8]\n",
      "\n",
      "Label:\n",
      " 0\n",
      "\n",
      "\n",
      "Text: \n",
      " A rating of \"1\" does not begin to express how dull, depressing and relentlessly bad this movie is.\n",
      "\n",
      "Tokens: \n",
      " ['a', 'rating', 'of', '1', 'does', 'not', 'begin', 'to', 'express', 'how', 'dull', 'depressing', 'and', 'relentlessly', 'bad', 'this', 'movie', 'is']\n",
      "\n",
      "Indices: \n",
      " [3, 512, 5, 241, 142, 24, 1095, 6, 2747, 83, 552, 2227, 4, 1, 59, 10, 13, 9]\n",
      "\n",
      "Label:\n",
      " 0\n",
      "\n",
      "\n",
      "Text: \n",
      " Smallville episode Justice is the best episode of Smallville ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! It's my favorite episode of Smallville! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "\n",
      "Tokens: \n",
      " ['smallville', 'episode', 'justice', 'is', 'the', 'best', 'episode', 'of', 'smallville', 'it', 's', 'my', 'favorite', 'episode', 'of', 'smallville']\n",
      "\n",
      "Indices: \n",
      " [1, 340, 1308, 9, 2, 91, 340, 5, 1, 8, 16, 47, 352, 340, 5, 1]\n",
      "\n",
      "Label:\n",
      " 1\n",
      "\n",
      "\n",
      "Text: \n",
      " Smallville episode Justice is the best episode of Smallville ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! It's my favorite episode of Smallville! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "\n",
      "Tokens: \n",
      " ['smallville', 'episode', 'justice', 'is', 'the', 'best', 'episode', 'of', 'smallville', 'it', 's', 'my', 'favorite', 'episode', 'of', 'smallville']\n",
      "\n",
      "Indices: \n",
      " [1, 340, 1308, 9, 2, 91, 340, 5, 1, 8, 16, 47, 352, 340, 5, 1]\n",
      "\n",
      "Label:\n",
      " 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data0 = [datum for datum in train_data if len(datum[1]) < 20 and datum[-1] == 0] # negative\n",
    "sample_data1 = [datum for datum in train_data if len(datum[1]) < 20 and datum[-1] == 1] # positive\n",
    "\n",
    "# we sample 2 tuples each from positive set and negative set\n",
    "sample_data = random.sample(sample_data0, 2) + random.sample(sample_data1, 2)\n",
    "for text, tokens, indices, label in sample_data:\n",
    "    print('Text: \\n {}\\n'.format(text))\n",
    "    print('Tokens: \\n {}\\n'.format(tokens))\n",
    "    print('Indices: \\n {}\\n'.format(indices))\n",
    "    print('Label:\\n {}\\n'.format(label))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      " Smallville episode Justice is the best episode of Smallville ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! It's my favorite episode of Smallville! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "\n",
      "Tokens: \n",
      " ['smallville', 'episode', 'justice', 'is', 'the', 'best', 'episode', 'of', 'smallville', 'it', 's', 'my', 'favorite', 'episode', 'of', 'smallville']\n",
      "\n",
      "Indices: \n",
      " [1, 340, 1308, 9, 2, 91, 340, 5, 1, 8, 16, 47, 352, 340, 5, 1]\n",
      "\n",
      "Label:\n",
      " 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(text, tokens, indices, label) = sample_data[-1]\n",
    "print('Text: \\n {}\\n'.format(text))\n",
    "print('Tokens: \\n {}\\n'.format(tokens))\n",
    "print('Indices: \\n {}\\n'.format(indices))\n",
    "print('Label:\\n {}\\n'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn import RNNClassifier\n",
    "\n",
    "\n",
    "# Define a Dataset Class for train, val and test set\n",
    "train_dataset = SentimentDataset(train_data)\n",
    "val_dataset = SentimentDataset(val_data)\n",
    "test_dataset = SentimentDataset(test_data)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "  train_dataset, batch_size=16, collate_fn=collate, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "  val_dataset, batch_size=16, collate_fn=collate, drop_last=False\n",
    ")\n",
    "\n",
    "model=RNNClassifier(len(vocab),50,100,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.5981\n",
      "Epoch [2/15], Loss: 0.6810\n",
      "Epoch [3/15], Loss: 0.5833\n",
      "Epoch [4/15], Loss: 0.6748\n",
      "Epoch [5/15], Loss: 0.5485\n",
      "Epoch [6/15], Loss: 0.4387\n",
      "Epoch [7/15], Loss: 0.5424\n",
      "Epoch [8/15], Loss: 0.5390\n",
      "Epoch [9/15], Loss: 0.3579\n",
      "Epoch [10/15], Loss: 0.4201\n",
      "Epoch [11/15], Loss: 0.3791\n",
      "Epoch [12/15], Loss: 0.3297\n",
      "Epoch [13/15], Loss: 0.4006\n",
      "Epoch [14/15], Loss: 0.5939\n",
      "Epoch [15/15], Loss: 0.3993\n",
      "训练完成！\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-4)\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader,1):\n",
    "        inputs = data['data'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "        lengths= data['lengths']\n",
    "\n",
    "        outputs = model(inputs,lengths)\n",
    "        loss = bce_loss(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"训练完成！\") #0.5 acc :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 / 193\n",
      "accuracy on test set: 0.8663639312358092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_accuracy(model, data_loader):\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    for i, x in enumerate(data_loader):\n",
    "        input = x['data'].to(device)\n",
    "        lengths = x['lengths']\n",
    "        label = x['label'].to(device)\n",
    "        pred = model(input, lengths)\n",
    "        corrects += ((pred > 0.5) == label).sum().item()\n",
    "        total += label.numel()\n",
    "        \n",
    "        if i > 0  and i % 100 == 0:\n",
    "            print('Step {} / {}'.format(i, len(data_loader)))\n",
    "    \n",
    "    return corrects / total\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  test_dataset, batch_size=16, collate_fn=collate, drop_last=False\n",
    ")\n",
    "\n",
    "print(\"accuracy on test set: {}\".format(compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I like the film\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment -> :), Confidence -> 0.7520840764045715\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bad quality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment -> :(, Confidence -> 0.7139485776424408\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " the film is not good enough \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment -> :(, Confidence -> 0.618679404258728\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    }
   ],
   "source": [
    "from sentiment_data import tokenize\n",
    "\n",
    "text = ''\n",
    "w2i = vocab\n",
    "while True:\n",
    "    text = input()\n",
    "    if text == 'exit':\n",
    "        break\n",
    "\n",
    "    words = torch.tensor([\n",
    "        w2i.get(word, w2i['<unk>'])\n",
    "        for word in tokenize(text)\n",
    "    ]).long().to(device).view(-1, 1)  # T x B\n",
    "\n",
    "    pred = model(words).item()\n",
    "    sent = pred > 0.5\n",
    "    \n",
    "    print('Sentiment -> {}, Confidence -> {}'.format(\n",
    "        ':)' if sent else ':(', pred if sent else 1 - pred\n",
    "    ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "base2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
